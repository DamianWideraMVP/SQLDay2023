{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "sqlday2023synapse"
		},
		"DemoLearn_AccountKey_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'DemoLearn_AccountKey'"
		},
		"sqlday2023synapse-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'sqlday2023synapse-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:sqlday2023synapse.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"DemoLearn_AKV_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://itechdayadla.dfs.core.windows.net"
		},
		"DemoLearn_AccountKey_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://itechdayadla.dfs.core.windows.net"
		},
		"SQLDay_AKV_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://sqlday2023akv.vault.azure.net/"
		},
		"sqlday2023synapse-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://sqlday2023.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/DemoLearn_AKV')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('DemoLearn_AKV_properties_typeProperties_url')]",
					"accountKey": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "SQLDay_AKV",
							"type": "LinkedServiceReference"
						},
						"secretName": "DemoLearnKey"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/SQLDay_AKV')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DemoLearn_AccountKey')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('DemoLearn_AccountKey_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('DemoLearn_AccountKey_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLDay_AKV')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('SQLDay_AKV_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sqlday2023synapse-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('sqlday2023synapse-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sqlday2023synapse-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('sqlday2023synapse-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/event source data example')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n    TOP 100 *\nFROM\n    OPENROWSET(\n        BULK 'https://sqlday2023.dfs.core.windows.net/bronze/202305/20230502.export.CSV',\n        FORMAT = 'CSV',\n        FIELDTERMINATOR = '\\t',\n        PARSER_VERSION = '2.0'\n    ) AS [result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Spark job sample')]",
			"type": "Microsoft.Synapse/workspaces/sparkJobDefinitions",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"targetBigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"requiredSparkVersion": "3.3",
				"language": "python",
				"scanFolder": false,
				"jobProperties": {
					"name": "Spark job sample",
					"file": "abfss://synapse@sqlday2023.dfs.core.windows.net/spark_job.py",
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "98762765-218f-44b3-b6cd-94e2f81e1aca",
						"spark.synapse.context.sjdname": "Spark job sample"
					},
					"args": [
						"abfss://raw@sqlday2023.dfs.core.windows.net/AWInternetSales.csv",
						"abfss://bronze@sqlday2023.dfs.core.windows.net/AWorks"
					],
					"jars": [],
					"pyFiles": [
						""
					],
					"files": [],
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/01 Create resources')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "02 Load to Delta"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "e50034e1-1c0c-4ca0-a786-b00a1b40dbe8"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": true
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pandas as pd"
						],
						"outputs": [],
						"execution_count": 33
					},
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"src_location = 'abfss://bronze@sqlday2023.dfs.core.windows.net/201*/*.CSV'\r\n",
							"dst_location = 'abfss://silver@sqlday2023.dfs.core.windows.net/gdeltevents/history/'"
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "python"
							},
							"collapsed": false
						},
						"source": [
							"%%pyspark\r\n",
							"df_events = spark.read.load(src_location, format='csv'\r\n",
							"## If header exists uncomment line below\r\n",
							"##, header=True\r\n",
							", sep = '\\t'\r\n",
							")\r\n",
							"display(df_events.limit(10))"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df_events = df_events.toDF('GlobalEventID'\r\n",
							",'Day'\r\n",
							",'MonthYear'\r\n",
							",'Year'\r\n",
							",'FractionDate'\r\n",
							",'Actor1Code'\r\n",
							",'Actor1Name'\r\n",
							",'Actor1CountryCode'\r\n",
							",'Actor1KnownGroupCode'\r\n",
							",'Actor1EthnicCode'\r\n",
							",'Actor1Religion1Code'\r\n",
							",'Actor1Religion2Code'\r\n",
							",'Actor1Type1Code'\r\n",
							",'Actor1Type2Code'\r\n",
							",'Actor1Type3Code'\r\n",
							",'Actor2Code'\r\n",
							",'Actor2Name'\r\n",
							",'Actor2CountryCode'\r\n",
							",'Actor2KnownGroupCode'\r\n",
							",'Actor2EthnicCode'\r\n",
							",'Actor2Religion1Code'\r\n",
							",'Actor2Religion2Code'\r\n",
							",'Actor2Type1Code'\r\n",
							",'Actor2Type2Code'\r\n",
							",'Actor2Type3Code'\r\n",
							",'IsRootEvent'\r\n",
							",'EventCode'\r\n",
							",'EventBaseCode'\r\n",
							",'EventRootCode'\r\n",
							",'QuadClass'\r\n",
							",'GoldsteinScale'\r\n",
							",'NumMentions'\r\n",
							",'NumSources'\r\n",
							",'NumArticles'\r\n",
							",'AvgTone'\r\n",
							",'Actor1Geo_Type'\r\n",
							",'Actor1Geo_Fullname'\r\n",
							",'Actor1Geo_CountryCode'\r\n",
							",'Actor1Geo_ADM1Code'\r\n",
							",'Actor1Geo_Lat'\r\n",
							",'Actor1Geo_Long'\r\n",
							",'Actor1Geo_FeatureID'\r\n",
							",'Actor2Geo_Type'\r\n",
							",'Actor2Geo_Fullname'\r\n",
							",'Actor2Geo_CountryCode'\r\n",
							",'Actor2Geo_ADM1Code'\r\n",
							",'Actor2Geo_Lat'\r\n",
							",'Actor2Geo_Long'\r\n",
							",'Actor2Geo_FeatureID'\r\n",
							",'ActionGeo_Type'\r\n",
							",'ActionGeo_Fullname'\r\n",
							",'ActionGeo_CountryCode'\r\n",
							",'ActionGeo_ADM1Code'\r\n",
							",'ActionGeo_Lat'\r\n",
							",'ActionGeo_Long'\r\n",
							",'ActionGeo_FeatureID'\r\n",
							",'DATEADDED'\r\n",
							",'SOURCEURL')\r\n",
							"# df_events.columns = new_column_names\r\n",
							"print(df_events.columns)"
						],
						"outputs": [],
						"execution_count": 36
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df_events.write.option(\"path\", dst_location).format(\"delta\").save()"
						],
						"outputs": [],
						"execution_count": 37
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LoadData do not use on sqlday')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "other"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "1b2c7194-d592-463b-8918-0b00d56f3e25"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pip install zipfile36"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\r\n",
							"import requests\r\n",
							"import pandas as pd\r\n",
							"import zipfile\r\n",
							"import io\r\n",
							"from datetime import datetime, timedelta"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sas_token = f'sp=racwdlm&st=2023-04-22T21:20:01Z&se=2023-05-31T05:20:01Z&spr=https&sv=2021-12-02&sr=c&sig=7Hb04rR6uzijvOjHdc70Xt9vyt4iEPx5i3AnoE20f%2Fg%3D'\r\n",
							"account = 'https://sqlday2023.blob.core.windows.net'\r\n",
							"url_base = 'http://data.gdeltproject.org/events/'\r\n",
							"container = 'data'\r\n",
							"unizpped_container = 'data/unizpped'\r\n",
							"file_extension = 'csv'"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_blob_service_client_sas( account, sas_token):\r\n",
							"    account_url = account\r\n",
							"    credential = sas_token\r\n",
							"    blob_service_client = BlobServiceClient(account_url, credential=credential)\r\n",
							"\r\n",
							"    return blob_service_client"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def send_data_to_blob (container_client: ContainerClient, fileName:str):\n",
							"    url = url_base+fileName\n",
							"\n",
							"\n",
							"    print (f'url: {url}')\n",
							"\n",
							"    file = fileName.split('.')[0]\n",
							"    file_to_save = file +'.'+file_extension\n",
							"\n",
							"    r = requests.get(url, allow_redirects=True)\n",
							"    zipDocument = zipfile.ZipFile(io.BytesIO(r.content))  \n",
							"    \n",
							"    listOfFileNames = zipDocument.namelist()\n",
							"\n",
							"    for file in listOfFileNames:\n",
							"        tmp = zipDocument.extract(file)\n",
							"        print (f'file: {file}, p={tmp}')\n",
							"\n",
							"        f = open (tmp,\"r\")\n",
							"        content = f.read()\n",
							"\n",
							"        blob_client = container_client.upload_blob(name=file, data=content, overwrite=True, blob_type=\"BlockBlob\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _create_nested_container_client(blob_service_client: BlobServiceClient, container_name: str, subfolder: str):\n",
							"    new_name_for_container = container_name + \"/\" + subfolder[0:6]\n",
							"    return blob_service_client.get_container_client(container=new_name_for_container)\n",
							"    \n",
							"    "
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_blob_file_1979_2005(blob_service_client: BlobServiceClient, container_name):\r\n",
							"    container_client = blob_service_client.get_container_client(container=container_name)\r\n",
							"\r\n",
							"    for dt in range(1979,2006,1):\r\n",
							"        dt_str = str(dt)+'.zip'\r\n",
							"        send_data_to_blob(container_client,dt_str)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 36
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_blob_file_200601_201303(blob_service_client: BlobServiceClient, container_name: str):\n",
							"\n",
							"    for dt in pd.period_range(start='2006-01-01', end='2013-03-01', freq='M'):\n",
							"        dt_str = str(dt).replace(\"-\",\"\")+'.zip'\n",
							"\n",
							"        container_client = _create_nested_container_client(blob_service_client, container_name, dt_str)\n",
							"        \n",
							"        send_data_to_blob(container_client,dt_str)"
						],
						"outputs": [],
						"execution_count": 46
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_blob_file_20130401_20230331(blob_service_client: BlobServiceClient, container_name):\n",
							"    container_client = blob_service_client.get_container_client(container=container_name) \n",
							"\n",
							"    for dt in pd.period_range(start='2014-02-01', end='2023-03-31', freq='D'):\n",
							"        dt_str = str(dt).replace(\"-\",\"\")+'.export.CSV.zip'\n",
							"\n",
							"        container_client = _create_nested_container_client(blob_service_client, container_name, dt_str)\n",
							"        \n",
							"        send_data_to_blob(container_client,dt_str)"
						],
						"outputs": [],
						"execution_count": 83
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_blob_file_for_dates(blob_service_client: BlobServiceClient, container_name: str, date_start:str, date_end:str):\n",
							"    '''date_start and date_end in format YYYY-MM-DD'''\n",
							"\n",
							"    for dt in pd.period_range(start=date_start, end=date_end, freq='D'):\n",
							"        dt_str = str(dt).replace(\"-\",\"\")+'.export.CSV.zip'\n",
							"\n",
							"        container_client = _create_nested_container_client(blob_service_client, container_name, dt_str)\n",
							"        \n",
							"        send_data_to_blob(container_client,dt_str)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_last_X_days(blob_service_client: BlobServiceClient, container_name: str, days: int):\n",
							"    end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
							"    start_date = (datetime.today() - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
							"\n",
							"    upload_blob_file_for_dates(blob_service_client, container_name,start_date,end_date )\n",
							"\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"bsc = get_blob_service_client_sas(account,sas_token)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"upload_blob_file_for_dates(bsc,unizpped_container, '2023-04-20','2023-04-29')"
						],
						"outputs": [],
						"execution_count": 116
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"upload_last_X_days(bsc,unizpped_container,7)"
						],
						"outputs": [],
						"execution_count": 13
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Raw  data ingestion')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "a942ea1b-8f24-484d-8523-8654c04ae082"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": true
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\r\n",
							"import requests\r\n",
							"import pandas as pd\r\n",
							"import zipfile\r\n",
							"import io\r\n",
							"from datetime import datetime, timedelta"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#(bronze)sas_token = f'sp=racwdlmeop&st=2023-05-03T11:20:20Z&se=2023-05-31T19:20:20Z&spr=https&sv=2021-12-02&sr=c&sig=SITj%2FKFPa%2FTLJgawl6TeqABXjTpimz9WcH62TPyxKss%3D'\r\n",
							"sas_token = f'sp=racwdlmeop&st=2023-05-03T21:02:46Z&se=2023-05-31T05:02:46Z&spr=https&sv=2021-12-02&sr=c&sig=8CY7pN26Rsto5wDJoYUM4RzofvxNaozEwpZWARTqVs0%3D'\r\n",
							"account = 'https://sqlday2023.blob.core.windows.net'\r\n",
							"url_base = 'http://data.gdeltproject.org/events/'\r\n",
							"unizpped_container = 'raw'\r\n",
							"file_extension = 'csv'"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_blob_service_client_sas( account, sas_token):\r\n",
							"    account_url = account\r\n",
							"    credential = sas_token\r\n",
							"    blob_service_client = BlobServiceClient(account_url, credential=credential)\r\n",
							"\r\n",
							"    return blob_service_client"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def send_data_to_blob (container_client: ContainerClient, fileName:str):\n",
							"    url = url_base+fileName\n",
							"\n",
							"\n",
							"    print (f'url: {url}')\n",
							"\n",
							"    file = fileName.split('.')[0]\n",
							"    file_to_save = file +'.'+file_extension\n",
							"\n",
							"    r = requests.get(url, allow_redirects=True)\n",
							"    zipDocument = zipfile.ZipFile(io.BytesIO(r.content))  \n",
							"    \n",
							"    listOfFileNames = zipDocument.namelist()\n",
							"\n",
							"    for file in listOfFileNames:\n",
							"        tmp = zipDocument.extract(file)\n",
							"        print (f'file: {file}, p={tmp}')\n",
							"\n",
							"        f = open (tmp,\"r\")\n",
							"        content = f.read()\n",
							"\n",
							"        blob_client = container_client.upload_blob(name=file, data=content, overwrite=True, blob_type=\"BlockBlob\")"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _create_nested_container_client(blob_service_client: BlobServiceClient, container_name: str, subfolder: str):\n",
							"    new_name_for_container = container_name + \"/\" + subfolder[0:6]\n",
							"    return blob_service_client.get_container_client(container=new_name_for_container)\n",
							"    \n",
							"    "
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_blob_file_for_dates(blob_service_client: BlobServiceClient, container_name: str, date_start:str, date_end:str):\n",
							"    '''date_start and date_end in format YYYY-MM-DD'''\n",
							"\n",
							"    for dt in pd.period_range(start=date_start, end=date_end, freq='D'):\n",
							"        dt_str = str(dt).replace(\"-\",\"\")+'.export.CSV.zip'\n",
							"\n",
							"        container_client = _create_nested_container_client(blob_service_client, container_name, dt_str)\n",
							"        \n",
							"        send_data_to_blob(container_client,dt_str)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_last_X_days(blob_service_client: BlobServiceClient, container_name: str, days: int):\n",
							"    \n",
							"    end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
							"    start_date = (datetime.today() - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
							"\n",
							"    upload_blob_file_for_dates(blob_service_client, container_name,start_date,end_date )\n",
							"\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"bsc = get_blob_service_client_sas(account,sas_token)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"upload_blob_file_for_dates(bsc,unizpped_container,'2023-03-24','2023-03-31')"
						],
						"outputs": [],
						"execution_count": 46
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"upload_last_X_days(bsc,unizpped_container,7)"
						],
						"outputs": [],
						"execution_count": 12
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Raw ingestion AKV')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "db280dcc-9a87-487f-9113-69396329b51b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": true
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"mssparkutils.notebook.run(\"utils/authorization_self\", 10)"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"akv_account = account"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"bsc = get_blob_service_client_sas(account,sas_token)"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"upload_last_X_days(bsc,container,7)"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/configuration_paramaters_raw_bronze')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils/configuration"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "6d94d5b1-7af1-4996-88f7-56985b1d07e2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from dataclasses import dataclass\n",
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"@dataclass\n",
							"class configuration_parameters_raw_bronze:\n",
							"    DATALAKE: str\n",
							"    RAW_CONTAINER: str\n",
							"    BRONZE_CONTAINER: str\n",
							"    RAW_SASKEY: str\n",
							"    BRONZE_SASKEY: str\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"PARAMETERS = configuration_parameters_raw_bronze (\n",
							"DATALAKE=\"https://sqlday2023.blob.core.windows.net\",\n",
							"RAW_CONTAINER=\"raw\",\n",
							"BRONZE_CONTAINER=\"bronze\",\n",
							"RAW_SASKEY=mssparkutils.credentials.getSecret('sqlday2023akv','SQLDayRaw','SQLDay_AKV'),\n",
							"BRONZE_SASKEY=mssparkutils.credentials.getSecret('sqlday2023akv','SQLDayBronze','SQLDay_AKV')\n",
							")"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/configuration_parameters')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils/configuration"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "cbdedfee-f09e-4c8a-b722-64839adaa2bd"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from dataclasses import dataclass\n",
							"\n",
							"@dataclass\n",
							"class configuration_parameters:\n",
							"    DATALAKE: str\n",
							"    CONTAINER: str\n",
							"    SASKEY: str\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"PARAMETERS = configuration_parameters (\n",
							"DATALAKE=\"https://itechdayadla.blob.core.windows.net\",\n",
							"CONTAINER=\"demolearn\",\n",
							"SASKEY=r\"?sv=2022-11-02&ss=bfqt&srt=sc&sp=rwdlacupyx&se=2023-05-31T09:27:54Z&st=2023-05-06T01:27:54Z&spr=https&sig=kvedG7707y8H%2FE8ZNsrEIOl7L2AhS3X0QEqtXi0GoJg%3D\"\n",
							")"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/configuration_parameters_akv')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils/configuration"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "70316932-054b-4a86-9a5c-8a514c3c1746"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from dataclasses import dataclass\n",
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"@dataclass\n",
							"class configuration_parameters_akv:\n",
							"    DATALAKE: str\n",
							"    CONTAINER: str\n",
							"    SASKEY: str"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"PARAMETERS = configuration_parameters_akv (\n",
							"DATALAKE=\"https://itechdayadla.blob.core.windows.net\",\n",
							"CONTAINER=\"demolearn\",\n",
							"SASKEY=mssparkutils.credentials.getSecret('sqlday2023akv','DemoLearnKey','SQLDay_AKV')\n",
							")"
						],
						"outputs": [],
						"execution_count": 7
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/configuration_parameters_local')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils/configuration"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c44c95fc-5810-41c6-9bf3-d77d74d17d97"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from dataclasses import dataclass\n",
							"\n",
							"@dataclass\n",
							"class configuration_parameters_local:\n",
							"    DATALAKE: str\n",
							"    CONTAINER: str\n",
							"    SASKEY: str\n",
							"    URL: str\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"PARAMETERS = configuration_parameters_local (\n",
							"DATALAKE=\"https://sqlday2023.blob.core.windows.net\",\n",
							"CONTAINER=\"raw\",\n",
							"SASKEY=f'sp=racwdlmeop&st=2023-05-03T21:02:46Z&se=2023-05-31T05:02:46Z&spr=https&sv=2021-12-02&sr=c&sig=8CY7pN26Rsto5wDJoYUM4RzofvxNaozEwpZWARTqVs0%3D',\n",
							"URL= 'http://data.gdeltproject.org/events/'\n",
							")"
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/configuration_parameters_local_akv')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils/configuration"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "42d015dd-4f20-457a-a94e-c59cfa4fe2be"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"from dataclasses import dataclass\n",
							"\n",
							"@dataclass\n",
							"class configuration_parameters_local:\n",
							"    DATALAKE: str\n",
							"    CONTAINER: str\n",
							"    SASKEY: str\n",
							"    URL: str\n",
							""
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"PARAMETERS = configuration_parameters_local (\n",
							"DATALAKE=\"https://sqlday2023.blob.core.windows.net\",\n",
							"CONTAINER=\"raw\",\n",
							"SASKEY=mssparkutils.credentials.getSecret('sqlday2023akv','SQLDayRaw','SQLDay_AKV'),\n",
							"URL= 'http://data.gdeltproject.org/events/'\n",
							")"
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/load_raw_authorization_akv')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "61cd56b8-c86b-48d5-9e97-5b101b28190b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": true
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
							"import requests\n",
							"import pandas as pd\n",
							"import zipfile\n",
							"import io\n",
							"from datetime import datetime, timedelta\n",
							"\n",
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run utils/configuration/configuration_parameters_local_akv"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_configuration():\n",
							"    return PARAMETERS.DATALAKE, PARAMETERS.SASKEY, PARAMETERS.CONTAINER, PARAMETERS.URL"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_blob_service_client_sas( account: str, sas_token: str) -> BlobServiceClient:\n",
							"    account_url = account\n",
							"    credential = sas_token\n",
							"    blob_service_client = BlobServiceClient(account_url, credential=credential)\n",
							"\n",
							"    return blob_service_client"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _send_data_to_blob (container_client: ContainerClient, fileName:str):\n",
							"    url = url_base+fileName\n",
							"\n",
							"\n",
							"    print (f'url: {url}')\n",
							"\n",
							"    file = fileName.split('.')[0]\n",
							"    file_to_save = file +'.'+file_extension\n",
							"\n",
							"    r = requests.get(url, allow_redirects=True)\n",
							"    zipDocument = zipfile.ZipFile(io.BytesIO(r.content))  \n",
							"    \n",
							"    listOfFileNames = zipDocument.namelist()\n",
							"\n",
							"    for file in listOfFileNames:\n",
							"        tmp = zipDocument.extract(file)\n",
							"        print (f'file: {file}, p={tmp}')\n",
							"\n",
							"        f = open (tmp,\"r\")\n",
							"        content = f.read()\n",
							"\n",
							"        blob_client = container_client.upload_blob(name=file, data=content, overwrite=True, blob_type=\"BlockBlob\")"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _create_nested_container_client(blob_service_client: BlobServiceClient, container_name: str, subfolder: str) -> ContainerClient:\n",
							"    new_name_for_container = container_name + \"/\" + subfolder[0:6]\n",
							"    return blob_service_client.get_container_client(container=new_name_for_container)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_blob_file_for_dates(blob_service_client: BlobServiceClient, container_name: str, date_start:str, date_end:str):\n",
							"    '''date_start and date_end in format YYYY-MM-DD'''\n",
							"\n",
							"    for dt in pd.period_range(start=date_start, end=date_end, freq='D'):\n",
							"        dt_str = str(dt).replace(\"-\",\"\")+'.export.CSV.zip'\n",
							"\n",
							"        container_client = _create_nested_container_client(blob_service_client, container_name, dt_str)\n",
							"        \n",
							"        _send_data_to_blob(container_client,dt_str)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_last_X_days(blob_service_client: BlobServiceClient, container_name: str, days: int):\n",
							"    \n",
							"    end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
							"    start_date = (datetime.today() - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
							"\n",
							"    upload_blob_file_for_dates(blob_service_client, container_name,start_date,end_date )\n",
							""
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"account ,sas_token, container, url_base = get_configuration()\n",
							"\n",
							"file_extension = 'csv'"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"bsc = get_blob_service_client_sas(account,sas_token)"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"upload_last_X_days(bsc,container,7)"
						],
						"outputs": [],
						"execution_count": 16
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/load_raw_authorization_external')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "81f2bdc6-b3b6-4632-a65f-d2cc1c227627"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
							"import requests\n",
							"import pandas as pdimport io\n",
							"from datetime import datetime, timedelta\n",
							"\n",
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"%run utils/configuration/configuration_parameters"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_configuration():\n",
							"    return PARAMETERS.DATALAKE, PARAMETERS.SASKEY, PARAMETERS.CONTAINER"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_blob_service_client_sas( account: str, sas_token: str) -> BlobServiceClient:\n",
							"    account_url = account\n",
							"    credential = sas_token\n",
							"    blob_service_client = BlobServiceClient(account_url, credential=credential)\n",
							"\n",
							"    return blob_service_client"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_blob_service_source_client_sas( account: str, sas_token: str) -> BlobServiceClient:\n",
							"    account_url = account\n",
							"    credential = sas_token\n",
							"    blob_service_client = BlobServiceClient(account_url, credential=credential)\n",
							"\n",
							"    return blob_service_client"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/load_raw_authorization_sas')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "873eb561-c608-4448-b5c7-bc670818e805"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
							"import requests\n",
							"import pandas as pd\n",
							"import zipfile\n",
							"import io\n",
							"from datetime import datetime, timedelta\n",
							"\n",
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": 54
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run utils/configuration/configuration_parameters_local"
						],
						"outputs": [],
						"execution_count": 55
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_configuration():\n",
							"    return PARAMETERS.DATALAKE, PARAMETERS.SASKEY, PARAMETERS.CONTAINER, PARAMETERS.URL"
						],
						"outputs": [],
						"execution_count": 56
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_blob_service_client_sas( account: str, sas_token: str) -> BlobServiceClient:\n",
							"    account_url = account\n",
							"    credential = sas_token\n",
							"    blob_service_client = BlobServiceClient(account_url, credential=credential)\n",
							"\n",
							"    return blob_service_client"
						],
						"outputs": [],
						"execution_count": 57
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _send_data_to_blob (container_client: ContainerClient, fileName:str):\n",
							"    url = url_base+fileName\n",
							"\n",
							"\n",
							"    print (f'url: {url}')\n",
							"\n",
							"    file = fileName.split('.')[0]\n",
							"    file_to_save = file +'.'+file_extension\n",
							"\n",
							"    r = requests.get(url, allow_redirects=True)\n",
							"    zipDocument = zipfile.ZipFile(io.BytesIO(r.content))  \n",
							"    \n",
							"    listOfFileNames = zipDocument.namelist()\n",
							"\n",
							"    for file in listOfFileNames:\n",
							"        tmp = zipDocument.extract(file)\n",
							"        print (f'file: {file}, p={tmp}')\n",
							"\n",
							"        f = open (tmp,\"r\")\n",
							"        content = f.read()\n",
							"\n",
							"        blob_client = container_client.upload_blob(name=file, data=content, overwrite=True, blob_type=\"BlockBlob\")"
						],
						"outputs": [],
						"execution_count": 58
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _create_nested_container_client(blob_service_client: BlobServiceClient, container_name: str, subfolder: str) -> ContainerClient:\n",
							"    new_name_for_container = container_name + \"/\" + subfolder[0:6]\n",
							"    return blob_service_client.get_container_client(container=new_name_for_container)"
						],
						"outputs": [],
						"execution_count": 59
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_blob_file_for_dates(blob_service_client: BlobServiceClient, container_name: str, date_start:str, date_end:str):\n",
							"    '''date_start and date_end in format YYYY-MM-DD'''\n",
							"\n",
							"    for dt in pd.period_range(start=date_start, end=date_end, freq='D'):\n",
							"        dt_str = str(dt).replace(\"-\",\"\")+'.export.CSV.zip'\n",
							"\n",
							"        container_client = _create_nested_container_client(blob_service_client, container_name, dt_str)\n",
							"        \n",
							"        _send_data_to_blob(container_client,dt_str)"
						],
						"outputs": [],
						"execution_count": 60
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def upload_last_X_days(blob_service_client: BlobServiceClient, container_name: str, days: int):\n",
							"    \n",
							"    end_date = (datetime.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
							"    start_date = (datetime.today() - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
							"\n",
							"    upload_blob_file_for_dates(blob_service_client, container_name,start_date,end_date )\n",
							""
						],
						"outputs": [],
						"execution_count": 61
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"account ,sas_token, container, url_base = get_configuration()\n",
							"\n",
							"file_extension = 'csv'"
						],
						"outputs": [],
						"execution_count": 62
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"bsc = get_blob_service_client_sas(account,sas_token)"
						],
						"outputs": [],
						"execution_count": 63
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"upload_last_X_days(bsc,container,7)"
						],
						"outputs": [],
						"execution_count": 64
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/load_raw_to_bronze_authorization_sas')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"folder": {
					"name": "01 Load raw data/utils"
				},
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "smallpool",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "f3a96319-1c15-4981-a4d1-0a7d5be6b873"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/f173fd35-dfcd-4ef5-902e-a0345aa77c84/resourceGroups/SQLDay2023/providers/Microsoft.Synapse/workspaces/sqlday2023synapse/bigDataPools/smallpool",
						"name": "smallpool",
						"type": "Spark",
						"endpoint": "https://sqlday2023synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/smallpool",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": true
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
							"import os\n",
							"from notebookutils import mssparkutils"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"%run utils/configuration/configuration_paramaters_raw_bronze"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_configuration():\n",
							"    return PARAMETERS.DATALAKE, PARAMETERS.RAW_CONTAINER, PARAMETERS.BRONZE_CONTAINER, PARAMETERS.RAW_SASKEY, PARAMETERS.BRONZE_SASKEY\n",
							""
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def get_blob_service_client_sas( account: str, sas_token: str) -> BlobServiceClient:\n",
							"    account_url = account\n",
							"    credential = sas_token\n",
							"    blob_service_client = BlobServiceClient(account_url, credential=credential)\n",
							"\n",
							"    return blob_service_client"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"account , raw_container, bronze_container, raw_sas_token, bronze_sas_token = get_configuration()\n",
							""
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"account , raw_container, bronze_container, raw_sas_token, bronze_sas_token"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"raw_bsc = get_blob_service_client_sas(account,raw_sas_token)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"bronze_bsc = get_blob_service_client_sas(account,bronze_sas_token)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _get_container_client(blob_service_client: BlobServiceClient, url: str, secret: str) -> ContainerClient:\n",
							"\n",
							"    sas_key = secret\n",
							"    if '?' not in sas_key:\n",
							"        sas_key = '?'+sas_key\n",
							"    container_client = ContainerClient.from_container_url(url+sas_key)\n",
							"    return container_client"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def _prepare_paths_for_data_processing (account: str, raw_container: str, bronze_container: str, folder: str, file_name: str):\n",
							"\n",
							"    #abfss://raw@sqlday2023.dfs.core.windows.net/customer/part-00000-tid-3200334632332214470-9b4dec79-7e2e-495d-8657-3b5457ed3753-108-1-c000.csv\n",
							"    #abfss://bronze@sqlday2023.dfs.core.windows.net/AWorks\n",
							"\n",
							"\n",
							"    account_for_abfss = account.split('://')[-1].replace(\"blob\",\"dfs\")\n",
							"        \n",
							"    path_to_blob_raw = \"abfss://\" + raw_container + \"@\" + account_for_abfss+\"/\"+ folder +\"/\"+file_name\n",
							"    path_to_blob_bronze = \"abfss://\" + bronze_container + \"@\" + account_for_abfss+\"/\"+ folder\n",
							"    return account_for_abfss, path_to_blob_raw, path_to_blob_bronze"
						],
						"outputs": [],
						"execution_count": 72
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"folders = [\"customer\",\"orders\"]"
						],
						"outputs": [],
						"execution_count": 67
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"for folder in folders:\n",
							"    full_path_raw = account + \"/\" + raw_container \n",
							"    full_path_bronze = account + \"/\" + bronze_container + \"/\" + folder\n",
							"\n",
							"    raw_container_client = _get_container_client(raw_bsc, full_path_raw, raw_sas_token)\n",
							"    bronze_container_client = _get_container_client(raw_bsc,full_path_bronze, bronze_sas_token )\n",
							"\n",
							"    blob_list = raw_container_client.list_blobs(name_starts_with=folder) \n",
							"\n",
							"\n",
							"    for item in blob_list:\n",
							"        blob = os.path.basename(item.name )\n",
							"\n",
							"        account_for_abfss, path_to_blob_raw, path_to_blob_bronze = _prepare_paths_for_data_processing(account, raw_container, bronze_container, folder, blob)\n",
							"\n",
							"        if 'csv' in path_to_blob_raw:\n",
							"            print (path_to_blob_raw)        \n",
							"            df = spark.read.load(path_to_blob_raw, format='csv', header=True)\n",
							"            df.write.mode(\"append\").parquet(path_to_blob_bronze)\n",
							"        \n",
							""
						],
						"outputs": [],
						"execution_count": 73
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/smallpool')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 0,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.3",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/sqlpool')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "westeurope"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/broze vs raw compare')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "-- This is auto-generated code\nSELECT\n     COUNT(*)\nFROM\n    OPENROWSET(\n        BULK 'https://sqlday2023.dfs.core.windows.net/bronze/customer/*.parquet',\n        FORMAT = 'PARQUET'\n    ) AS [result]\nGO\nSELECT\n    COUNT(*) \nFROM\n    OPENROWSET(\n        BULK 'https://sqlday2023.dfs.core.windows.net/raw/customer/*.csv',\n        FORMAT = 'CSV',\n        PARSER_VERSION = '2.0'\n    ) AS [result]\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		}
	]
}